# AI Clinical Advisory Crew

## Description
This project implements a system for analyzing and improving patient experience in healthcare environments, using a team of specialized AI agents. The system processes patient feedback, analyzes healthcare processes, evaluates emotional states, and proposes improvements in communication and processes. 

A key feature of this project is the flexibility to swap out different LLM (Large Language Model) configurations for testing various outputs. Each agent can utilize a different LLM, allowing for the combination of multiple agents with distinct models in the process, enhancing the overall analysis and recommendations.

## Agents
The project utilizes five specialized agents:

1. Patient Experience Expert
2. Health & IT Process Expert
3. Clinical Psychologist
4. Communication Expert
5. Manager and Advisor

Each agent has a specific role in analyzing and improving the patient experience.

# AI Clinical Advisory Crew Report Structure

The report generated by the AI Clinical Advisory Crew is structured to provide a comprehensive analysis of patient feedback and recommendations for improvement. Each report is divided into several sections, each focusing on different aspects of the patient experience and the healthcare process:

1. **Patient Feedback**: 
   - This section captures the patient's experience in their own words, detailing specific issues encountered during their interaction with the healthcare provider.

2. **Agent Analysis**: 
   - Each specialized agent provides their analysis based on the patient feedback. The agents include:
     - **Patient Experience Expert**: Focuses on the emotional impact of the experience and identifies key issues.
     - **Health & IT Process Expert**: Analyzes the patient journey, identifies inefficiencies, and suggests process improvements.
     - **Clinical Psychologist**: Assesses the emotional state of the patient and recommends support strategies.
     - **Communication Expert**: Evaluates the quality of communication and identifies areas for improvement.
     - **Manager and Advisor**: Provides a consolidated communication report with actionable recommendations.

3. **Final Recommendations**: 
   - Each agent concludes with specific recommendations aimed at improving the patient experience, communication, and overall service quality.

4. **Execution Time**: 
   - The report concludes with the total execution time taken to generate the report.

## Configuration
The project uses the Ollama models for natural language processing:

- **llama_model**: Meta's Llama 3.1 8B is a state-of-the-art language model known for its balance between performance and efficiency. It excels in natural language processing tasks such as text generation and question answering, benefiting from Meta's leading AI research.

- **hermes_model**: NousResearch's Hermes 3 8B is designed for advanced reasoning and conversation. It uses the ChatML format, allowing greater control over interactions, making it a top choice for dialogue-intensive tasks requiring nuanced understanding.

- **phi_model**: Microsoft's Phi-3.5 Mini 3.8B is a lightweight model built for high performance in reasoning and language comprehension tasks. Trained on synthetic and high-quality datasets, it’s optimized for efficiency and excels in complex analytical scenarios.

- **gemma_model**: Google's Gemma 2 9B strikes an excellent balance between size and performance, making it ideal for a wide range of natural language processing tasks. It showcases Google's commitment to scalable and accessible AI solutions.

- **openhermes_model**: OpenHermes by NousResearch is built for superior text generation and assistant capabilities. It improves on context understanding and response coherence, providing robust performance for advanced conversational applications.

- **mistral_model**: Mistral AI's Mistral NeMo 12B, developed with NVIDIA, features a 128k token context window. It excels in reasoning, knowledge retention, and precise coding, offering a powerful solution for tasks requiring deep contextual analysis.

- **quwen_model**: Alibaba's Qwen2 7B is a multilingual model supporting 29 languages with a 128k token context window. It’s highly adaptable for natural language processing tasks, providing reliable performance in multilingual applications.

- **llava_model**: LLaVA (Large Language and Vision Assistant) 7B integrates visual and language understanding. Built on Meta’s LLaMA architecture, it handles tasks like visual question answering and image captioning, making it versatile for multimodal use cases.

- **zephyr_model**: Zephyr 7B from Hugging Face is based on the Mistral-7B-v0.1 architecture and optimized using Direct Preference Optimization (DPO). It excels in following detailed instructions and conversational tasks, outperforming many larger models in benchmarks like MT-Bench and AlpacaEval.


## Requirements
- Python 3.8+
- Dependencies listed in `requirements.txt`

## Installation
1. Clone the repository
2. Install the dependencies:
   ```
   pip install -r requirements.txt
   ```

## Usage
Run the main script:
```
python main.py
```

The script reads patient feedback from `patient_feedback.txt` and performs analysis through the AI agent team.

## Project Structure
- `main.py`: Main script
- `config/`: Project configurations
- `agents/`: Agent definitions
- `tasks/`: Task definitions
- `utils.py`: Utility functions

## Contributing
Contributions are welcome. Please open an issue to discuss proposed changes.

## License
[MIT](https://choosealicense.com/licenses/mit/)
